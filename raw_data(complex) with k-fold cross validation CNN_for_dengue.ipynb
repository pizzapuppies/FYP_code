{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pizzapuppies/Usif_FYP_code/blob/main/raw_data(complex)%20with%20k-fold%20cross%20validation%20CNN_for_dengue.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "predictive ANN for solution\n"
      ],
      "metadata": {
        "id": "h2F9z_KZUYyq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K5yS4kCjFFnz"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd \n",
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np  \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import csv\n",
        "import random\n",
        "from tensorflow import keras\n",
        "import sys\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "p5hrzLr-gD8i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebcd7cf2-627e-4a8c-a55e-2f6651b97d31"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mat = [[1,2,3],[4,5,6]]\n",
        "\n",
        "def split23(li):\n",
        "  g = []\n",
        "  for i in range(1,len(li),3):\n",
        "    g.append(li[i:i+3])\n",
        "  return g"
      ],
      "metadata": {
        "id": "9OKNg_S92-3n"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "\n",
        "with open('/content/gdrive/My Drive/FYP Dengue data - Sheet1.csv', 'r') as f:\n",
        "  csv_reader = csv.reader(f, delimiter=',')\n",
        "  line_count = 0\n",
        "    \n",
        "  for i in csv_reader:\n",
        "    if line_count == 0:\n",
        "      for j in range(len(split23(i))):\n",
        "        X.append([])\n",
        "      \n",
        "    line_count += 1\n",
        "    if i[0] in [\"index\",\"conc\",\"label\"]:\n",
        "            if i[0] == \"label\":\n",
        "              y = split23(i)\n",
        "    else:\n",
        "      li = split23(i)\n",
        "      \n",
        "      for ind,dat in enumerate(li):\n",
        "        com = list(map(float,dat[1:]))\n",
        "        X[ind].append(complex(com[0],com[1]))\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "for i,li in enumerate(y):\n",
        "  if li[0] == \"1\":\n",
        "    y[i] = 1\n",
        "  else:\n",
        "    y[i] = 0\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "temp = list(zip(X, y))\n",
        "random.shuffle(temp)\n",
        "X, y = zip(*temp)\n",
        "X, y = list(X), list(y)\n",
        "X = np.array(X).astype('complex')\n",
        "y = np.array(y)"
      ],
      "metadata": {
        "id": "yWr4SAQGy5pw"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "impedance py did the math but did not output the parameters"
      ],
      "metadata": {
        "id": "vxFRYUBe3w-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def learn_test(X_train,Y_train,X_test,Y_test):\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(keras.layers.Dense(128,         #Number of nodes\n",
        "                        input_shape=(50,1), #Number of input variables\n",
        "                        name='Hidden-Layer-1', #Logical name\n",
        "                        activation='relu'))    #activation function\n",
        "\n",
        "  #Add a second hidden layer\n",
        "  model.add(keras.layers.Dense(128,\n",
        "                                name='Hidden-Layer-2',\n",
        "                                activation='relu'))\n",
        "\n",
        "  model.add(tf.keras.layers.Conv1D(\n",
        "      2,3,activation='relu'\n",
        "  ))\n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "  #Add a second hidden layer\n",
        "  model.add(keras.layers.Dense(128,\n",
        "                                name='Hidden-Layer-3',\n",
        "                                activation='relu'))\n",
        "\n",
        "\n",
        "\n",
        "  #Add a second hidden layer\n",
        "  model.add(keras.layers.Dense(128,\n",
        "                                name='Hidden-Layer-4',\n",
        "                              activation='relu'))\n",
        "  \n",
        "  model.add(keras.layers.Dense(1,\n",
        "                             name='Output-Layer',\n",
        "                             activation='sigmoid'))\n",
        "\n",
        "  model.compile(loss= tf.keras.losses.BinaryCrossentropy() ,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "  #Make it verbose so we can see the progress\n",
        "  VERBOSE=0\n",
        "\n",
        "  #Setup Hyper Parameters for training\n",
        "\n",
        "  #Set Batch size\n",
        "  BATCH_SIZE=16\n",
        "  #Set number of epochs\n",
        "  EPOCHS=20\n",
        "  #Set validation split. 20% of the training data will be used for validation\n",
        "  #after each epoch\n",
        "  VALIDATION_SPLIT=0.2\n",
        "\n",
        "  #Fit the model. This will perform the entire training cycle, including\n",
        "  #forward propagation, loss computation, backward propagation and gradient descent.\n",
        "  #Execute for the specified batch sizes and epoch\n",
        "  #Perform validation after each epoch \n",
        "  history=model.fit(X_train,\n",
        "            Y_train,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            epochs=EPOCHS,\n",
        "            verbose=VERBOSE,\n",
        "            validation_split=VALIDATION_SPLIT)\n",
        "  \n",
        "  #Evaluate the model against the test dataset and print results\n",
        "  print(\"\\nEvaluation against Test Dataset :\\n------------------------------------\")\n",
        "  z = model.evaluate(X_test,Y_test)\n",
        "  print(\"The accuracy of the model is \",round(z[1]*100),\" %\")\n",
        "  return round(z[1]*100)"
      ],
      "metadata": {
        "id": "5VtED6jYMkJj"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "n_split=10\n",
        "\n",
        "li = []\n",
        "\n",
        "for train_index,test_index in KFold(n_split).split(X):\n",
        "  x_train,x_test=X[train_index],X[test_index]\n",
        "  y_train,y_test=y[train_index],y[test_index]\n",
        "  xa = learn_test(x_train,y_train,x_test,y_test)\n",
        "  li.append(xa)"
      ],
      "metadata": {
        "id": "by4pnG1IMgXF",
        "outputId": "192a8d83-55e0-4585-c91b-a60f8194c9b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation against Test Dataset :\n",
            "------------------------------------\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.7008 - accuracy: 0.4286\n",
            "The accuracy of the model is  43  %\n",
            "\n",
            "Evaluation against Test Dataset :\n",
            "------------------------------------\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.7025 - accuracy: 0.3571\n",
            "The accuracy of the model is  36  %\n",
            "\n",
            "Evaluation against Test Dataset :\n",
            "------------------------------------\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.7058 - accuracy: 0.3571\n",
            "The accuracy of the model is  36  %\n",
            "\n",
            "Evaluation against Test Dataset :\n",
            "------------------------------------\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.6938 - accuracy: 0.4286\n",
            "The accuracy of the model is  43  %\n",
            "\n",
            "Evaluation against Test Dataset :\n",
            "------------------------------------\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.7457 - accuracy: 0.1429\n",
            "The accuracy of the model is  14  %\n",
            "\n",
            "Evaluation against Test Dataset :\n",
            "------------------------------------\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "The accuracy of the model is  50  %\n",
            "\n",
            "Evaluation against Test Dataset :\n",
            "------------------------------------\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.6939 - accuracy: 0.4286\n",
            "The accuracy of the model is  43  %\n",
            "\n",
            "Evaluation against Test Dataset :\n",
            "------------------------------------\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "The accuracy of the model is  50  %\n",
            "\n",
            "Evaluation against Test Dataset :\n",
            "------------------------------------\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.6937 - accuracy: 0.3571\n",
            "The accuracy of the model is  36  %\n",
            "\n",
            "Evaluation against Test Dataset :\n",
            "------------------------------------\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 6.1928e-08 - accuracy: 1.0000\n",
            "The accuracy of the model is  100  %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(max(li))"
      ],
      "metadata": {
        "id": "4aT9LM5mGaIf",
        "outputId": "bd4eb467-575f-42b5-9955-673e29c8a322",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n"
          ]
        }
      ]
    }
  ]
}