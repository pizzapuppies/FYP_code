{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "f3BvEppnj-mj"
      ],
      "authorship_tag": "ABX9TyPvJDfdAAyeqkWk+7PQrAhp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pizzapuppies/Usif_FYP_code/blob/main/RD_hyper_tuned_concentration_predictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q -U keras-tuner"
      ],
      "metadata": {
        "id": "RRfHFfIMTkFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mAZzJuAlYBE"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd \n",
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np  \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import csv\n",
        "import random\n",
        "from tensorflow import keras\n",
        "import sys\n",
        "import keras_tuner as kt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data preprocessing"
      ],
      "metadata": {
        "id": "4yVmJ0-aj6J0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data in the csv needs to transposed and split into training and testing"
      ],
      "metadata": {
        "id": "c3XE5jCb12An"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title spliting the data\n",
        "train_test_split = \"10%\" #@param [\"10%\", \"20%\"]\n",
        "data = []\n",
        "with open(\"/content/FYP Dengue data - Sheet1(3).csv\",\"r\") as rfile:\n",
        "  line = 0\n",
        "\n",
        "  reader  = csv.reader(rfile)\n",
        "  real,imag = [],[]\n",
        "  \n",
        "  for i in reader:\n",
        "\n",
        "    if line> 55:\n",
        "      #print(line,i)\n",
        "      if line%3 == 0:\n",
        "\n",
        "        imag = i[3:53]\n",
        "        label = f\"p{i[1]}\" if i[2] == \"1\" else f\"n{i[1]}\"\n",
        "        data.append([label]+ real+imag)\n",
        "        real,imag = [],[]\n",
        "      elif line%3 == 2:\n",
        "        real = i[3:53]\n",
        "        \n",
        "\n",
        "    line += 1\n",
        "\n",
        "data = np.array(data)\n",
        "\n",
        "test,train = [],[]\n",
        "count = random.randint(0,10)\n",
        "\n",
        "spl = 10 if train_test_split == '10%' else 5\n",
        "\n",
        "for i in data:\n",
        "  if count%spl == 0:  ## This line controls the train_test split (10 for 10%, 5 for 20%)\n",
        "    test.append(i)\n",
        "  else: train.append(i) \n",
        "  count += 1\n",
        "\n",
        "test = np.array(test)\n",
        "train = np.array(train)\n",
        "\n",
        "with open(\"train_data.csv\",\"w\") as wfile:\n",
        "  writer = csv.writer(wfile)\n",
        "  for i in train:\n",
        "    writer.writerow(i)\n",
        "with open(\"test_data.csv\",\"w\") as wfile:\n",
        "  writer = csv.writer(wfile)\n",
        "  for i in test:\n",
        "    writer.writerow(i)"
      ],
      "metadata": {
        "id": "aswX90pexUWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title extracting the training data + one hot encoding the labels\n",
        "y = []\n",
        "x = []\n",
        "\n",
        "with open(\"train_data.csv\",\"r\") as tfile:\n",
        "  reader = csv.reader(tfile)\n",
        "  for i in reader:\n",
        "    \n",
        "    y.append(i[0])\n",
        "\n",
        "    a,b = list(map(float,i[1:51])),list(map(float,i[51:]))\n",
        "    x.append([a,b])\n",
        "\n",
        "x = np.array(x)\n",
        "y = np.array(y)\n",
        "\n",
        "\n",
        "temp = list(zip(x, y))\n",
        "random.shuffle(temp)\n",
        "x, y = zip(*temp)\n",
        "x, y = list(x), list(y)\n",
        "x = np.array(x)\n",
        "y = np.array(y)\n",
        "\n",
        "print(\"the shape of X is\",x.shape)\n",
        "\n",
        "\n",
        "#@title one hot encoding Y\n",
        "\n",
        "mapping = {}\n",
        "codes = list(set(y))\n",
        "l = len(codes)\n",
        "\n",
        "for i in range(l):\n",
        "  li = [0]*l\n",
        "  \n",
        "  li[i] = 1\n",
        "  \n",
        "  mapping[codes[i]] = np.array(li)\n",
        "\n",
        "temp = []\n",
        "for i in y:\n",
        "  temp.append(mapping[i])\n",
        "\n",
        "y = np.array(temp)\n",
        "\n",
        "print(\"The shape of Y is\",y.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZoL8SDdKBGH",
        "outputId": "81f4de04-95f1-47c0-c3af-ecd8bc33335e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the shape of X is (126, 2, 50)\n",
            "The shape of Y is (126, 14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# building and runnning the model"
      ],
      "metadata": {
        "id": "f3BvEppnj-mj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_builder(hp):\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(keras.layers.Dense(128,         #Number of nodes\n",
        "                        input_shape=(2,50), #Number of input variables\n",
        "                        name='Hidden-Layer-1', #Logical name\n",
        "                        activation='relu'))    #activation function\n",
        "\n",
        "  hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
        "  \n",
        "  #Add a second hidden layer\n",
        "  model.add(keras.layers.Dense(units=hp_units,\n",
        "                                name='Hidden-Layer-2',\n",
        "                                activation='relu',\n",
        "                                ))\n",
        "\n",
        "  \n",
        "\n",
        "  #Add a second hidden layer\n",
        "  model.add(keras.layers.Dense(128,\n",
        "                                name='Hidden-Layer-3',\n",
        "                                activation='relu'))\n",
        "\n",
        "\n",
        "\n",
        "  #Add a second hidden layer\n",
        "  model.add(keras.layers.Dense(128,\n",
        "                                name='Hidden-Layer-4',\n",
        "                              activation='relu'))\n",
        "  \n",
        "  model.add(keras.layers.Dense(128,\n",
        "                                name='Hidden-Layer-5',\n",
        "                              activation='relu'))\n",
        "  \n",
        "  model.add(keras.layers.Dense(128,\n",
        "                                name='Hidden-Layer-6',\n",
        "                              activation='relu'))\n",
        "\n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  model.add(keras.layers.Dense(14,\n",
        "                             name='Output-Layer',\n",
        "                             activation='softmax'))\n",
        "\n",
        "  # Tune the number of units in the first Dense layer\n",
        "  # Choose an optimal value between 32-512\n",
        "  \n",
        "  \n",
        "\n",
        "  # Tune the learning rate for the optimizer\n",
        "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
        "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
        "                loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model\n",
        "\n",
        "def learn_test(X_train,Y_train,X_test,Y_test):\n",
        "  \n",
        "\n",
        "  tuner = kt.Hyperband(model_builder,\n",
        "                     objective='val_accuracy',\n",
        "                     max_epochs=10,\n",
        "                     factor=3,\n",
        "                     directory='my_dir',\n",
        "                     project_name='intro_to_kt')\n",
        "\n",
        "  stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "  tuner.search(X_train, Y_train, epochs=150, validation_split=0.2, callbacks=[stop_early])\n",
        "\n",
        "  # Get the optimal hyperparameters\n",
        "  best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "  #print(f\n",
        "  \"\"\"\n",
        "  The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
        "  layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
        "  is {best_hps.get('learning_rate')}.\n",
        "  )\"\"\"\n",
        "\n",
        " # Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
        "  model = tuner.hypermodel.build(best_hps)\n",
        "  history = model.fit(X_train, Y_train, epochs=50, validation_split=0.2)\n",
        "\n",
        "  val_acc_per_epoch = history.history['val_accuracy']\n",
        "  best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
        "  print('Best epoch: %d' % (best_epoch,))\n",
        "\n",
        "  hypermodel = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "  # Retrain the model\n",
        "  hypermodel.fit(X_train, Y_train, epochs=best_epoch, validation_split=0.2)\n",
        "\n",
        "  eval_result = hypermodel.evaluate(X_test, Y_test)\n",
        "  print(\"[test loss, test accuracy]:\", eval_result)\n",
        "  return eval_result[1]\n"
      ],
      "metadata": {
        "id": "606tQbrLtBEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = []\n",
        "x_test = []\n",
        "with open(\"test_data.csv\",\"r\") as tfile:\n",
        "  reader = csv.reader(tfile)\n",
        "  for i in reader:\n",
        "    \n",
        "    y_test.append(i[0])\n",
        "    x_test.append([i[1:51],i[51:]])\n",
        "\n",
        "x_test = np.array(x)\n",
        "y_test = np.array(y)\n",
        "\n",
        "\n",
        "temp = list(zip(x, y))\n",
        "random.shuffle(temp)\n",
        "x_test, y_test = zip(*temp)\n",
        "x_test, y_test = list(x), list(y)\n",
        "x_test = np.array(x)\n",
        "y_test = np.array(y)"
      ],
      "metadata": {
        "id": "KI55CSZslwaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xa = learn_test(x,y,x_test,y_test)\n",
        "print(\"accuracy is \",round(xa*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klpYB0PbtrLn",
        "outputId": "78340ae9-79b4-49dd-96cc-f64d9f6a8b40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 30 Complete [00h 00m 03s]\n",
            "val_accuracy: 0.19230769574642181\n",
            "\n",
            "Best val_accuracy So Far: 0.26923078298568726\n",
            "Total elapsed time: 00h 01m 53s\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 2s 134ms/step - loss: 483.7935 - accuracy: 0.0700 - val_loss: 241.5589 - val_accuracy: 0.1538\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 246.4109 - accuracy: 0.1100 - val_loss: 118.7761 - val_accuracy: 0.1154\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 145.7537 - accuracy: 0.1300 - val_loss: 89.2318 - val_accuracy: 0.1154\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 109.2523 - accuracy: 0.1100 - val_loss: 62.0855 - val_accuracy: 0.2308\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 80.6291 - accuracy: 0.0600 - val_loss: 46.8305 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 61.5405 - accuracy: 0.0800 - val_loss: 39.2910 - val_accuracy: 0.0769\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 53.1232 - accuracy: 0.1300 - val_loss: 32.2758 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 42.0982 - accuracy: 0.1500 - val_loss: 29.0836 - val_accuracy: 0.1538\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 35.3070 - accuracy: 0.1400 - val_loss: 21.3579 - val_accuracy: 0.1154\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 26.0637 - accuracy: 0.2100 - val_loss: 17.6562 - val_accuracy: 0.1154\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 19.3423 - accuracy: 0.2000 - val_loss: 12.3355 - val_accuracy: 0.1154\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 14.0248 - accuracy: 0.1800 - val_loss: 10.6183 - val_accuracy: 0.0769\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 10.6247 - accuracy: 0.1800 - val_loss: 9.7477 - val_accuracy: 0.1538\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 10.2329 - accuracy: 0.2100 - val_loss: 7.9828 - val_accuracy: 0.1538\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 7.3459 - accuracy: 0.2200 - val_loss: 7.9843 - val_accuracy: 0.1538\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 7.6636 - accuracy: 0.2400 - val_loss: 8.9950 - val_accuracy: 0.1923\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 7.8906 - accuracy: 0.2000 - val_loss: 10.3264 - val_accuracy: 0.0769\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 7.3122 - accuracy: 0.2800 - val_loss: 8.1965 - val_accuracy: 0.2308\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 7.8164 - accuracy: 0.2400 - val_loss: 8.8064 - val_accuracy: 0.1538\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 5.6352 - accuracy: 0.2600 - val_loss: 8.0839 - val_accuracy: 0.3077\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 8.7499 - accuracy: 0.2900 - val_loss: 11.3263 - val_accuracy: 0.1154\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 7.0776 - accuracy: 0.2600 - val_loss: 12.0379 - val_accuracy: 0.0769\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 7.0462 - accuracy: 0.2600 - val_loss: 9.6021 - val_accuracy: 0.1923\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 6.3420 - accuracy: 0.2800 - val_loss: 8.8179 - val_accuracy: 0.1154\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 4.6214 - accuracy: 0.3200 - val_loss: 6.1463 - val_accuracy: 0.0385\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 3.8425 - accuracy: 0.3100 - val_loss: 5.1070 - val_accuracy: 0.3077\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 4.6024 - accuracy: 0.3400 - val_loss: 5.1203 - val_accuracy: 0.2308\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 5.0952 - accuracy: 0.2800 - val_loss: 5.5860 - val_accuracy: 0.1154\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 4.4998 - accuracy: 0.3200 - val_loss: 6.9400 - val_accuracy: 0.1538\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 4.4744 - accuracy: 0.3300 - val_loss: 6.2722 - val_accuracy: 0.3077\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 4.8703 - accuracy: 0.3500 - val_loss: 5.9032 - val_accuracy: 0.3846\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 4.6309 - accuracy: 0.3800 - val_loss: 6.6455 - val_accuracy: 0.1538\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 5.3417 - accuracy: 0.3100 - val_loss: 6.1737 - val_accuracy: 0.1923\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 5.1558 - accuracy: 0.3400 - val_loss: 4.8489 - val_accuracy: 0.2308\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 4.8490 - accuracy: 0.2900 - val_loss: 6.4170 - val_accuracy: 0.1538\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 5.0681 - accuracy: 0.2700 - val_loss: 5.3783 - val_accuracy: 0.1538\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 3.6623 - accuracy: 0.4000 - val_loss: 7.1323 - val_accuracy: 0.1923\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 4.7623 - accuracy: 0.3400 - val_loss: 4.9403 - val_accuracy: 0.3462\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 4.0752 - accuracy: 0.2900 - val_loss: 5.0627 - val_accuracy: 0.1154\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 3.2613 - accuracy: 0.3400 - val_loss: 5.2854 - val_accuracy: 0.3462\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 4.9502 - accuracy: 0.3100 - val_loss: 7.2909 - val_accuracy: 0.1923\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 4.8288 - accuracy: 0.3600 - val_loss: 5.0252 - val_accuracy: 0.2308\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 3.9625 - accuracy: 0.3400 - val_loss: 5.4482 - val_accuracy: 0.2308\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 4.1014 - accuracy: 0.3100 - val_loss: 7.9306 - val_accuracy: 0.1154\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 4.7917 - accuracy: 0.3300 - val_loss: 6.3430 - val_accuracy: 0.3077\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 3.8204 - accuracy: 0.4500 - val_loss: 7.4710 - val_accuracy: 0.2308\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 5.0363 - accuracy: 0.3800 - val_loss: 6.2854 - val_accuracy: 0.2692\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 3.7240 - accuracy: 0.4400 - val_loss: 5.4847 - val_accuracy: 0.2308\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 3.6289 - accuracy: 0.3700 - val_loss: 7.3599 - val_accuracy: 0.1154\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 4.8027 - accuracy: 0.2900 - val_loss: 7.6473 - val_accuracy: 0.1154\n",
            "Best epoch: 31\n",
            "Epoch 1/31\n",
            "4/4 [==============================] - 2s 128ms/step - loss: 318.2740 - accuracy: 0.0500 - val_loss: 184.4319 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/31\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 205.0164 - accuracy: 0.0900 - val_loss: 127.7226 - val_accuracy: 0.1923\n",
            "Epoch 3/31\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 154.3495 - accuracy: 0.1400 - val_loss: 95.0138 - val_accuracy: 0.1154\n",
            "Epoch 4/31\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 117.9169 - accuracy: 0.1100 - val_loss: 81.3506 - val_accuracy: 0.0385\n",
            "Epoch 5/31\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 96.9021 - accuracy: 0.0900 - val_loss: 59.2872 - val_accuracy: 0.1923\n",
            "Epoch 6/31\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 71.1436 - accuracy: 0.1200 - val_loss: 40.8127 - val_accuracy: 0.1538\n",
            "Epoch 7/31\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 53.2415 - accuracy: 0.1000 - val_loss: 33.8588 - val_accuracy: 0.2692\n",
            "Epoch 8/31\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 44.2109 - accuracy: 0.1600 - val_loss: 27.6044 - val_accuracy: 0.2308\n",
            "Epoch 9/31\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 33.6040 - accuracy: 0.1300 - val_loss: 20.3340 - val_accuracy: 0.1154\n",
            "Epoch 10/31\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 25.8841 - accuracy: 0.1300 - val_loss: 26.4185 - val_accuracy: 0.0769\n",
            "Epoch 11/31\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 26.3372 - accuracy: 0.1300 - val_loss: 23.8828 - val_accuracy: 0.1154\n",
            "Epoch 12/31\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 20.4917 - accuracy: 0.1300 - val_loss: 13.8315 - val_accuracy: 0.1538\n",
            "Epoch 13/31\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 13.8130 - accuracy: 0.1000 - val_loss: 9.9346 - val_accuracy: 0.3077\n",
            "Epoch 14/31\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 10.0173 - accuracy: 0.1700 - val_loss: 11.2655 - val_accuracy: 0.1154\n",
            "Epoch 15/31\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 10.0554 - accuracy: 0.2200 - val_loss: 11.3135 - val_accuracy: 0.0769\n",
            "Epoch 16/31\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 9.3412 - accuracy: 0.1900 - val_loss: 9.2819 - val_accuracy: 0.1923\n",
            "Epoch 17/31\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 8.5426 - accuracy: 0.2600 - val_loss: 10.4265 - val_accuracy: 0.1538\n",
            "Epoch 18/31\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 7.6976 - accuracy: 0.1900 - val_loss: 6.7059 - val_accuracy: 0.1538\n",
            "Epoch 19/31\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 5.5694 - accuracy: 0.2000 - val_loss: 7.6051 - val_accuracy: 0.1538\n",
            "Epoch 20/31\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 6.6866 - accuracy: 0.2400 - val_loss: 9.6956 - val_accuracy: 0.0769\n",
            "Epoch 21/31\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 6.6999 - accuracy: 0.2000 - val_loss: 10.4500 - val_accuracy: 0.1538\n",
            "Epoch 22/31\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 10.0810 - accuracy: 0.2700 - val_loss: 14.5137 - val_accuracy: 0.0385\n",
            "Epoch 23/31\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 10.2999 - accuracy: 0.1600 - val_loss: 9.3656 - val_accuracy: 0.1923\n",
            "Epoch 24/31\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 5.4037 - accuracy: 0.3200 - val_loss: 7.9733 - val_accuracy: 0.1923\n",
            "Epoch 25/31\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 7.8391 - accuracy: 0.3100 - val_loss: 8.8117 - val_accuracy: 0.1923\n",
            "Epoch 26/31\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 7.6370 - accuracy: 0.2700 - val_loss: 6.6910 - val_accuracy: 0.1923\n",
            "Epoch 27/31\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 6.1309 - accuracy: 0.3100 - val_loss: 11.3274 - val_accuracy: 0.0769\n",
            "Epoch 28/31\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 7.5928 - accuracy: 0.2900 - val_loss: 8.8027 - val_accuracy: 0.1923\n",
            "Epoch 29/31\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 6.0906 - accuracy: 0.3200 - val_loss: 7.5815 - val_accuracy: 0.1538\n",
            "Epoch 30/31\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 5.1781 - accuracy: 0.2600 - val_loss: 9.1291 - val_accuracy: 0.1538\n",
            "Epoch 31/31\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 5.2589 - accuracy: 0.3100 - val_loss: 8.9074 - val_accuracy: 0.1538\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 5.9697 - accuracy: 0.2778\n",
            "[test loss, test accuracy]: [5.969722747802734, 0.2777777910232544]\n",
            "accuracy is  28\n"
          ]
        }
      ]
    }
  ]
}